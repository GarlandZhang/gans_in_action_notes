{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cgan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOj998WeqRjMr0iUJf5vPtS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/gans_in_action_notes/blob/master/cgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdfIodng39RB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5aa55ce0-8a93-4664-c1b2-638dc2e8cc06"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Activation, BatchNormalization, Concatenate, Dense, Embedding, Flatten, Input, Multiply, Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTg-l1nY4bWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(z_dim):\n",
        "  model = Sequential([\n",
        "                      Dense(256 * 7 * 7, input_dim=z_dim),\n",
        "                      Reshape((7, 7, 256)),\n",
        "                      Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'),\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "                      Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'),\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "                      Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'),\n",
        "                      Activation('tanh')\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def build_cgan_generator(z_dim):\n",
        "  z = Input(shape=(z_dim, ))\n",
        "  label = Input(shape=(1, ), dtype='int32')\n",
        "  label_embedding = Embedding(num_classes, z_dim, input_length = 1)(label) # \" Label embedding: turns labels into dense vectors of size z_dim; produces 3D tensor with shape (batch_size, 1, z_dim)\" \n",
        "  label_embedding = Flatten()(label_embedding) # Flattens 3D tensor into 2D tensor (batch_size, z_dim)\n",
        "  joined_representation = Multiply()([z, label_embedding])\n",
        "  generator = build_generator(z_dim)\n",
        "  conditioned_img = generator(joined_representation) # generates image for given label\n",
        "  return Model([z, label], conditioned_img)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sSr9gF98cjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape):\n",
        "  combined_shape =  (img_shape[0], img_shape[1], img_shape[2] + 1)\n",
        "  model = Sequential([\n",
        "                      Conv2D(64, kernel_size=3, strides=2, input_shape=combined_shape, padding='same'), # 28 x 28 x 2 => 14 x 14 x 64\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "                      Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding='same'), # 14 x 14 x 64 => 7 x 7 x 64. we have input_shape=img_shape because...?\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "                      Conv2D(128, kernel_size=3, strides=2, input_shape=img_shape, padding='same'),\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "                      Flatten(),\n",
        "                      Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def build_cgan_discriminator(img_shape):\n",
        "  img = Input(shape=img_shape)\n",
        "  label = Input(shape=(1, ), dtype='int32')\n",
        "  label_embedding = Embedding(num_classes, np.prod(img_shape), input_length=1)(label)\n",
        "  label_embedding = Flatten()(label_embedding)\n",
        "  label_embedding = Reshape(img_shape)(label_embedding)\n",
        "  concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "  discriminator = build_discriminator(img_shape)\n",
        "  classification = discriminator(concatenated)\n",
        "  return Model([img, label], classification)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvPCNwLECqBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cgan(generator, discriminator):\n",
        "  z = Input(shape=(z_dim, ))\n",
        "  label = Input(shape=(1, ))\n",
        "  img = generator([z, label])\n",
        "  classification = discriminator([img, label])\n",
        "  return Model([z, label], classification)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r48fLK05RLS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "  (x_train, y_train), _ = mnist.load_data()\n",
        "  x_train = x_train / 127.5 - 1.\n",
        "  x_train = np.expand_dims(x_train, axis=3)\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  for iteration in range(iterations):\n",
        "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "    imgs, labels = x_train[idx], y_train[idx]\n",
        "\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "    gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "    disc_real_loss = discriminator.train_on_batch([imgs, labels], real)\n",
        "    disc_fake_loss = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "\n",
        "    disc_loss = 0.5 * np.add(disc_real_loss, disc_fake_loss)\n",
        "\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "\n",
        "    labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "\n",
        "    gen_loss = cgan.train_on_batch([z, labels], real)\n",
        "\n",
        "    if (iteration + 1) % sample_interval == 0:\n",
        "      print(f'{iteration + 1} [D loss: {disc_loss[0]}, acc.: {100 * disc_loss[1]}] [G loss: {gen_loss}]')\n",
        "      losses.append((disc_loss[0], gen_loss))\n",
        "      accuracies.append(100 * disc_loss[1])\n",
        "      sample_images()\n",
        "\n",
        "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
        "  z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "  labels = np.arange(0, 10).reshape(-1, 1)\n",
        "  gen_imgs = generator.predict([z, labels])\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "  fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(10, 4), sharey=True, sharex=True)\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for i in range(image_grid_rows):\n",
        "    for j in range(image_grid_columns):\n",
        "      axs[i, j].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "      axs[i, j].set_title(f'Digit: {labels[count]}')\n",
        "      count += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x_fOgb84Qna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "img_channels = 1\n",
        "\n",
        "img_shape = (img_rows, img_cols, img_channels)\n",
        "\n",
        "z_dim = 100\n",
        "\n",
        "num_classes = 10"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFRXJSX4aUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = build_cgan_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "generator = build_cgan_generator(z_dim)\n",
        "\n",
        "discriminator.trainable = False\n",
        "cgan = build_cgan(generator, discriminator)\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXNcIvK9X7Fm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "033edde2-6c9b-42cd-c281-36a40c0d414c"
      },
      "source": [
        "iterations = 12000\n",
        "batch_size = 32\n",
        "sample_interval = 1000\n",
        "\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000 [D loss: 0.002916002180427313, acc.: 100.0] [G loss: [21.705742, 0.0]]\n",
            "2000 [D loss: 0.0022667807061225176, acc.: 100.0] [G loss: [6.7411017, 0.0]]\n",
            "3000 [D loss: 0.1522151529788971, acc.: 93.75] [G loss: [3.205821, 0.0625]]\n",
            "4000 [D loss: 0.22683537006378174, acc.: 92.1875] [G loss: [0.6782111, 0.5625]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGRXp2LOZ0Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}