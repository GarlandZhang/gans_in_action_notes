{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sgan_impl.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUcAKo8GibvPrBJyQ9zRtI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarlandZhang/gans_in_action_notes/blob/master/sgan_impl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGekOX6lUpiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipope1FRU7mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MisMTA5TVbBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Activation, BatchNormalization, Concatenate, Dense, Dropout, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651jLTeWXnym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, num_labeled):\n",
        "    self.num_labeled = num_labeled\n",
        "    (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
        "\n",
        "    self.x_train = self.preprocess_imgs(self.x_train)\n",
        "    self.y_train = self.preprocess_labels(self.y_train)\n",
        "\n",
        "    self.x_test = self.preprocess_imgs(self.x_test)\n",
        "    self.y_test = self.preprocess_labels(self.y_test)\n",
        "\n",
        "  def preprocess_imgs(self, x):\n",
        "    x = x.astype(np.float32) / 127.5 - 1\n",
        "    x = np.expand_dims(x, axis=3)\n",
        "    return x\n",
        "\n",
        "  def preprocess_labels(self, y):\n",
        "    return y.reshape(-1, 1)\n",
        "\n",
        "  def batch_labeled(self, batch_size):\n",
        "    idx = np.random.randint(0, self.num_labeled, batch_size)\n",
        "    imgs = self.x_train[idx]\n",
        "    labels = self.y_train[idx]\n",
        "    return imgs, labels\n",
        "  \n",
        "  def batch_unlabeled(self, batch_size):\n",
        "    idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)\n",
        "    imgs = self.x_train[idx]\n",
        "    return imgs\n",
        "\n",
        "  def training_set(self):\n",
        "    x_train = self.x_train[range(self.num_labeled)] # self.x_train is the ACTUAL training set; this is OUR training set\n",
        "    y_train = self.y_train[range(self.num_labeled)]\n",
        "    return x_train, y_train\n",
        "\n",
        "  def test_set(self):\n",
        "    return x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_bCLBkezUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(z_dim):\n",
        "  model = Sequential([\n",
        "                      Dense(256 * 7 * 7, input_dim=z_dim),\n",
        "                      Reshape((7, 7, 256)),\n",
        "                      Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'), # 14 x 14 x 128\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "\n",
        "                      Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'), # 14 x 14 x 64\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "\n",
        "                      Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'), # 28 x 28 x 1\n",
        "                      Activation('tanh')                      \n",
        "\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNkd9Rsggu-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape, num_classes):\n",
        "  model = Sequential([\n",
        "                      Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same'),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "\n",
        "                      Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding='same'),\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "\n",
        "                      Conv2D(128, kernel_size=3, strides=2, input_shape=img_shape, padding='same'),\n",
        "                      BatchNormalization(),\n",
        "                      LeakyReLU(alpha=0.01),\n",
        "                      Dropout(0.5), # \"the dropout layer is added after batch normalization and not the other way around; this has shown to have superior performance due to the interplay between the two techniques\"\n",
        "                      Flatten(),\n",
        "                      Dense(num_classes)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvsuhJ_ElnO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_supervised(discriminator_net):\n",
        "  model = Sequential([\n",
        "                      discriminator_net,\n",
        "                      Activation('softmax')\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7P_hiH1mn7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_unsupervised(discriminator_net):\n",
        "  def predict(x): # \" we transform the output of the 10 neurons (from the core Discriminator network) into a binary, real-versus-fake prediction\"\n",
        "    prediction = 1. - (1. / (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.)) # suppose any of the x values are large; then we will have large divider so we have small value therefore we get 1 as output; otherwise if small theen we have 0 as output\n",
        "    return prediction\n",
        "\n",
        "  model = Sequential([\n",
        "                    discriminator_net,\n",
        "                    Lambda(predict)  \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS6wwe1FqpxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(generator, discriminator):\n",
        "  model = Sequential([\n",
        "                      generator,\n",
        "                      discriminator\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1toa6UkqrN6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_net = build_discriminator(img_shape, num_classes) # this is mutable so when we train supervised, it inherently trains unsupervised\n",
        "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
        "discriminator_supervised.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "discriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\n",
        "discriminator_unsupervised.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "generator = build_generator(z_dim)\n",
        "discriminator_unsupervised.trainable = False\n",
        "gan = build_gan(generator, discriminator_unsupervised)\n",
        "gan.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stURsI31ei3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "supervised_losses = []\n",
        "iteration_checkpoints = []\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "  for iteration in range(iterations):\n",
        "    imgs, labels = dataset.batch_labeled(batch_size)\n",
        "    labels = to_categorical(labels, num_classes=num_classes)\n",
        "    imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim)) # latent space vector\n",
        "    gen_imgs = generator.predict(z)\n",
        "    d_loss_supervised, sup_acc = discriminator_supervised.train_on_batch(imgs, labels)\n",
        "    d_loss_real, un_real_acc = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
        "    d_loss_fake, un_fake_acc = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
        "    d_loss_unsupervised = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "    g_loss = gan.train_on_batch(z, real)\n",
        "\n",
        "    if (iteration + 1) % sample_interval == 0:\n",
        "      supervised_losses.append(d_loss_supervised)\n",
        "      iteration_checkpoints.append(iteration + 1)\n",
        "      print('{iteration + 1} [D loss supervised: {d_loss_supervised}, acc.: {100 * sup_acc}] [D loss unsupervised: {d_loss_unsupervised}] [G loss: {g_loss}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgdp4pmzx2w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labeled = 100\n",
        "dataset = Dataset(num_labeled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkd-LF4xcNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "f5d0b999-65b0-4467-d078-3353826ae4a8"
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "z_dim = 100\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "iterations = 8000\n",
        "batch_size = 32\n",
        "sample_interval = 800\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8ec0243fabd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-51-3def3c28b9d7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(iterations, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;34m' unsupervised: %.4f] [G loss: %f]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 % (iteration + 1, d_loss_supervised, 100 * sup_acc,\n\u001b[0;32m---> 26\u001b[0;31m                   (d_loss_unsupervised, g_loss)))\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rataUQhvx2Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv0k7jFwxl-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}